---
title: "Data analysis"
date: "12/09/2023"
output: html_document
---

## Libraries

```{r library, message = FALSE}
library(tidyverse)
library(readr)
library(boot)
library(table1)
library(gridExtra)
library(MASS)
library(car)
```

## Data Clean

```{r data load}
breastcancer_data =
  read_csv("Project_2_data.csv") |>
  janitor::clean_names()
  
summary(breastcancer_data)
```

```{r data clean}
bc = breastcancer_data |>
  mutate(
    race=case_when(
      race == "White" ~ 1,
      race == "Black" ~ 2,
      race == "Other" ~ 3),
    marital_status=case_when(
      marital_status == "Married" ~ 1,
      marital_status == "Divorced" ~ 2,
      marital_status == "Single" ~ 3,
      marital_status == "Widowed" ~ 4,
      marital_status == "Separated" ~ 5),
    t_stage=case_when(
      t_stage == "T1" ~ 1,
      t_stage == "T2" ~ 2,
      t_stage == "T3" ~ 3,
      t_stage == "T4" ~ 4),
    n_stage=case_when(
      n_stage == "N1" ~ 1,
      n_stage == "N2" ~ 2,
      n_stage == "N3" ~ 3),
    x6th_stage=case_when(
      x6th_stage == "IIA" ~ 1,
      x6th_stage == "IIIA" ~ 2,
      x6th_stage == "IIIC" ~ 3,
      x6th_stage == "IIB" ~ 4,
      x6th_stage == "IIIB" ~ 5),
    differentiate=case_when(
      differentiate == "Poorly differentiated" ~ 1,
      differentiate == "Moderately differentiated" ~ 2,
      differentiate == "Well differentiated" ~ 3,
      differentiate == "Undifferentiated" ~ 4),
    grade=case_when(
      grade == "1" ~ 1,
      grade == "2" ~ 2,
      grade == "3" ~ 3,
      grade == "anaplastic; Grade IV" ~ 4),
    a_stage=case_when(
      a_stage == "Regional" ~ 1,
      a_stage == "Distant" ~ 0),
    estrogen_status=case_when(
      estrogen_status == "Positive" ~ 1,
      estrogen_status == "Negative" ~ 0),
    progesterone_status=case_when(
      progesterone_status == "Positive" ~ 1,
      progesterone_status == "Negative" ~ 0),
    status=case_when(
      status == "Alive" ~ 1,
      status == "Dead" ~ 0)
    ) 
```

## Descriptive statistics for all variables

```{r Descriptive statistics}
summary(bc)
```

We change race, marital_status, t_stage, n_stage, x6th_stage, differentiate, and grade into multiple numeric levels, while a_stage, estrogen_status, progesterone_status, and status to binary levels. The above variables are categorical variables.

And age, tumor_size, regional_node_examined, reginol_node_positive, and survival_months are numeric variables.

## Covariance and Correlation

```{r correlation}
plot(bc)

cor(bc) |>
  knitr::kable(digits=4,caption="Correlation for all variables")
```

## Exploratory visualisation

```{r age}
plot1age = 
  breastcancer_data|>
  ggplot(aes(x = age)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.5), binwidth = 5) +
  theme_minimal() +
  labs(
    title = "Age Distribution",
    x = "Age",
    y = "Frequency"
  )
plot1age
```

```{r race}
plot2race = 
  breastcancer_data|>
  ggplot(aes(x = race)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Race Distribution",
    x = "Race",
    y = "Frequency"
  )
plot2race
```

```{r marital}
plot3marital = 
  breastcancer_data|>
  ggplot(aes(x = marital_status)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Marital Status Distribution",
    x = "Marital Status",
    y = "Frequency"
  )

plot3marital
```

```{r tstage}
plot4tstage = 
  breastcancer_data|>
  ggplot(aes(x = t_stage)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "T Stage Distribution",
    x = "T Stage",
    y = "Frequency"
  )

plot4tstage
```

```{r nstage}
plot5nstage = 
  breastcancer_data|>
  ggplot(aes(x = n_stage)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "N Stage Distribution",
    x = "N Stage",
    y = "Frequency"
  )

plot5nstage
```

```{r x6thstage}
plot6x6thstage = 
  breastcancer_data|>
  ggplot(aes(x = x6th_stage)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "x6th Stage Distribution",
    x = "x6th Stage",
    y = "Frequency"
  )

plot6x6thstage
```

```{r differentate}
plot7differentate = 
  breastcancer_data|>
  ggplot(aes(x = differentiate)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Differentate Distribution",
    x = "Differentate Group",
    y = "Frequency"
  )

plot7differentate
```

```{r grade}
plot8grade = 
  breastcancer_data|>
  ggplot(aes(x = grade)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Grade Distribution",
    x = "Grade",
    y = "Frequency"
  )

plot8grade
```

```{r astage}
plot9astage = 
  breastcancer_data|>
  ggplot(aes(x = a_stage)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "A_stage Distribution",
    x = "A Stage",
    y = "Frequency"
  )

plot9astage
```


```{r tumorsize}
plot10tumorsize = 
  breastcancer_data|>
  ggplot(aes(x = tumor_size)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Tumor Size Distribution",
    x = "Tumor Size",
    y = "Frequency"
  )

plot10tumorsize
```

```{r estrogen}
plot11estrogen = 
  breastcancer_data|>
  ggplot(aes(x = estrogen_status)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Estrogen Status Distribution",
    x = "Estrogen Status",
    y = "Frequency"
  )

plot11estrogen
```

```{r progesterone}
plot12progesterone = 
  breastcancer_data|>
  ggplot(aes(x = progesterone_status)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Progesterone Status Distribution",
    x = "Progesterone Status",
    y = "Frequency"
  )

plot12progesterone
```

```{r nodeexamined}
plot13nodeexamined = 
  breastcancer_data|>
  ggplot(aes(x = regional_node_examined)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Regional Node Examined Distribution",
    x = "Examined Regional Node",
    y = "Frequency"
  )

plot13nodeexamined
```

```{r nodepositive}
plot14nodepositive = 
  breastcancer_data|>
  ggplot(aes(x = reginol_node_positive)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Regional Node Positive Distribution",
    x = "Positive Reginol Node",
    y = "Frequency"
  )

plot14nodepositive
```

Y1 = survive months; (numeric)

Y2 = status; (binary)

```{r survive months}
plot15survivalmonths = 
  breastcancer_data|>
  ggplot(aes(x = survival_months)) +
  geom_histogram(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "Survival Months",
    x = "Number of survival months",
    y = "Frequency"
  )

plot15survivalmonths
```

```{r status}
plot16status = 
  bc|>
  ggplot(aes(x = status)) +
  geom_bar(color = "blue", fill = alpha("blue", 0.5))+
  theme_minimal() +
  labs(
    title = "status",
    x = "status",
    y = "Frequency"
  )

plot16status
```

### Summarized plots

```{r numeric variables}
grid.arrange(plot1age, plot10tumorsize, plot13nodeexamined, 
             plot14nodepositive, ncol = 2)
```

We can see that age is approximately normal, while tumor size, regional node examined, and regional node positive are skewed. 

```{r categorical variables}
grid.arrange(plot2race, plot3marital,plot4tstage, 
             plot5nstage, plot6x6thstage,plot7differentate,
             plot8grade,plot9astage,plot11estrogen,plot12progesterone, ncol = 3)
```

## Transformation

We know that the tumor size, regional node examined, and regional node positive are skewed. We should do transformation on these variables. Before the transformation, we can use the Box-Cox plot to check which transformation work the best for them.

```{r boxcox}
bc_transform_tumorsize <- boxcox(breastcancer_data$tumor_size ~ 1, lambda = seq(-2, 2, by=0.1))
bc_transform_regionalnode_examined <- boxcox(breastcancer_data$regional_node_examined ~ 1, lambda = seq(-2, 2, by=0.1))
bc_transform_regionalnode_pos <- boxcox(breastcancer_data$reginol_node_positive ~ 1, lambda = seq(-2, 2, by=0.1))
```

The lambda value of tumor size is close to 0, so we should use log transformation, while the lambda value of regional node examined is around 0.5, we should take a square root to the value, and the lambda value of regional node positive is around -0.5, so we should take a take sqaure root and take an (-1) exponent for transformation. 

```{r transformation on numeric}
par(mfrow = c(2, 2)) 
hist(log(bc$tumor_size)) 
hist(sqrt(bc$regional_node_examined)) 
hist(bc$reginol_node_positive**(-0.5))
```

We can see that tumor size and regional node examined become approximately normal after log transformation, while the other one still extremely skewed. Therefore, we may consider not using the variable of reginol_node_positive. 




### Transformation model

```{r}
newbc1 = bc |>
  mutate(ln_tumor=log(tumor_size),
         sqrt_examined=sqrt(regional_node_examined)) |>
  dplyr::select(-tumor_size) |>
  dplyr::select(-regional_node_examined) |>
  dplyr::select(-status)
newbc1
```

```{r}
newbc2 = bc |>
  mutate(ln_tumor=log(tumor_size),
         sqrt_examined=sqrt(regional_node_examined)) |>
  dplyr::select(-tumor_size) |>
  dplyr::select(-regional_node_examined) |>
  dplyr::select(-survival_months)
newbc2
```

## Indicator Test

```{r}
# indicator test when y is status
categorical_vars <- c("race", "marital_status", "t_stage", "n_stage", "x6th_stage", 
                       "differentiate", "grade", "a_stage", 
                       "estrogen_status", "progesterone_status")

newbc2[categorical_vars] <- lapply(newbc2[categorical_vars], factor)

formula <- as.formula("status ~ race + marital_status + t_stage + n_stage + x6th_stage + 
                       differentiate + grade + a_stage + estrogen_status + progesterone_status+ln_tumor + sqrt_examined+ reginol_node_positive+ age")

model <- glm(formula, data = newbc2, family = binomial())

summary(model)
```
Based on the above indicator test summary, we delete grade and x6th_stage because their output was NA in the output linear model, since NA indicates these predicts may contribute colinearity. 



```{r}
# indicator test when y is Survival Months
categorical_vars <- c("race", "marital_status", "t_stage", "n_stage", "x6th_stage", 
                       "differentiate", "grade", "a_stage", 
                       "estrogen_status", "progesterone_status")

newbc1[categorical_vars] <- lapply(newbc1[categorical_vars], factor)
formula1 <- as.formula("survival_months ~ race + marital_status + t_stage + n_stage + x6th_stage + 
                       differentiate + grade + a_stage + estrogen_status + progesterone_status+ln_tumor + sqrt_examined+ reginol_node_positive+ age")

model1 <- lm(formula1, data = newbc1)

summary(model1)
```
Based on the above indicator test summary, we delete grade and x6th_stage.

## Model Fitting

### Initial Model

```{r linear fit}
lmfit=lm(survival_months ~ race + marital_status + t_stage + n_stage + differentiate  + a_stage + estrogen_status + progesterone_status+ln_tumor + sqrt_examined+ reginol_node_positive+ age, data = newbc1) 
summary(lmfit)

par(mfrow=c(2,2))
plot(lmfit)
```

```{r}
glmfit <- glm(status ~ race + marital_status + t_stage + n_stage + differentiate + 
               a_stage + estrogen_status + progesterone_status + ln_tumor + 
               sqrt_examined + reginol_node_positive + age, 
               data = newbc2, family = binomial)
summary(glmfit)
par(mfrow = c(2, 2))
plot(glmfit)
```

## Partial Test 

### Partial test for numeric Y

```{r global test on numeric Y}
# Our 1st global model for the predicts without colinearity and not normal predicts

model_global_num = lm(survival_months ~ race + marital_status + t_stage + n_stage + 
                       differentiate + a_stage + estrogen_status + progesterone_status+ln_tumor + sqrt_examined+age, newbc1)

summary(model_global_num)


```
From the summary of the global model, we can see that from the P-value of race, t_stage, differentiate, a_stage,  progesterone_status, ln_tumor, sqrt_examined, and age all have the p-value above 0.05 which is not significant. While sqrt_examined have a 0.0559 p-value which is a close call, so we may consider keep it. Since the covariates like marital_status, n_stage, estrogen_status have a P-value smaller than 0.05 indicating significance. Therefore, our 1st partial test may include the significant covariates. 

```{r partial test on numeric Y}

# 1st numeric partial test with all significant covariates
nummodel_partial_1 = lm(survival_months ~ marital_status + n_stage + estrogen_status + sqrt_examined, newbc1)

summary(nummodel_partial_1)

# 2nd numeric partial test with all in-significant covariates
nummodel_partial_2 = lm(survival_months ~ race + t_stage + differentiate + a_stage + progesterone_status + ln_tumor + age, newbc1)

summary(nummodel_partial_2)

# 3rd numeric partial test with some significant in 2nd test added 
nummodel_partial_3 = lm(survival_months ~ marital_status + n_stage + estrogen_status + sqrt_examined + a_stage + progesterone_status + ln_tumor, newbc1)

summary(nummodel_partial_3)

```
- Our 1st partial test only include the significant predicts on global test, and then we also did a second partial test includes all the covariates that are non significant, and we can see the 1st partial model has an adjusted R-squared of 0.03419 which is slightly lower than the global test with the same RSE to global test indicating a slightly underfitting. While the second model with all the non signifcant covraites only get an adjusted R-squared of 0.01859 which is much lower than the global test with a higher RSE, so we will definitely not use the model 2 combination. However, we do discover some covariates are significant on the second model like n_stage, and progesterone_status, so we include these 3 again onto the 1st model to get our 3rd model. Fortunately, our 3rd model has a highest adjusted R-squared value of 0.03714 and a lower RSE. 

### Partial Test for binary Y

```{r global test on binary Y}
# Our 1st global model for the predicts without colinearity and not normal predicts
model_global_bin = lm(status ~ race + marital_status + t_stage + n_stage + 
                       differentiate + a_stage +estrogen_status + progesterone_status + ln_tumor + sqrt_examined + age, newbc2)

summary(model_global_bin)

```
From the summary of the global model, we can see that from the P-value of race, x6th_stage, differentiate, a_stage, ln_tumor have the p-value above 0.05 which is not significant. While differentiate has a 0.053247 p-value which is a close call, we may consider keep it. Since the covariates like marital_status, t_stage, n_stage, grade, estrogen_status, progesterone_status, sqrt_examined, age have a P-value smaller than 0.05 indicating significance. Therefore, our 1st partial test may include the significant covariates. 


```{r partial test on binary Y}

# 1st binary partial test with all significant covariates
binmodel_partial_1 = lm(status ~ marital_status + t_stage + n_stage + differentiate + estrogen_status + progesterone_status + sqrt_examined + age, newbc2)

summary(binmodel_partial_1)

# 2nd binary partial test with all in-significant covariates
binmodel_partial_2 = lm(status ~ race +  a_stage + ln_tumor, newbc2)

summary(binmodel_partial_2)

# 3rd binary partial test with some significant in 2nd test added 
binmodel_partial_3 = lm(status ~ marital_status + t_stage + n_stage + differentiate + estrogen_status + progesterone_status + sqrt_examined + age + a_stage + ln_tumor, newbc2)

summary(binmodel_partial_3)

```
- Our 1st partial test only include the significant predicts on global test, and then we also did a second partial test includes all the covariates that are non significant, and we can see the 1st partial model has an adjusted R-squared of 0.1205 which equals that of the global test with the same RSE to global test. While the second model with all the non signifcant covraites only get an adjusted R-squared of 0.02442 which is much lower than the global test with a higher RSE, so we will definitely not use the model 2 combination. However, we do discover some covariates are significant on the second model like a_stage, and ln_tumor, so we include these 2 again into the 1st model to get our 3rd model. However, our 3rd model has a lower adjusted R-squared value of 0.1203 and a higher RSE, so we will continue to keep with global test or model 1.


## Step-wise: forward/backward/AiC

### Step-wise for numeric Y

```{r backward elimination on numeric Y}
numglobal_backward = stepAIC(model_global_num, direction = "backward")
num1_backward = stepAIC(nummodel_partial_1, direction = "backward")
num2_backward = stepAIC(nummodel_partial_2, direction = "backward")
num3_backward = stepAIC(nummodel_partial_3, direction = "backward")
```

```{r forward selection on numeric Y}
numglobal_backward = stepAIC(model_global_num, direction = "forward")
num1_backward = stepAIC(nummodel_partial_1, direction = "forward")
num2_backward = stepAIC(nummodel_partial_2, direction = "forward")
num3_backward = stepAIC(nummodel_partial_3, direction = "forward")
```
```{r stepwise regression on numeric Y}
numglobal_backward = stepAIC(model_global_num, direction = "both")
num1_backward = stepAIC(nummodel_partial_1, direction = "both")
num2_backward = stepAIC(nummodel_partial_2, direction = "both")
num3_backward = stepAIC(nummodel_partial_3, direction = "both")
```
- Above all, we can see that from all the backward, forward, and stepwise selection, we have the same AIC get from the 4 numerical model, and the best combination with the lowest AIC of 25062.62 is the combination of progesterone_status, a_stage, sqrt_examined, marital_status, ln_tumor, estrogen_status n_stage 

### Step-wise for binary Y

```{r backward elimination on binary Y}
binglobal_backward = stepAIC(model_global_bin, direction = "backward")
bin1_backward = stepAIC(binmodel_partial_1, direction = "backward")
bin2_backward = stepAIC(binmodel_partial_2, direction = "backward")
bin3_backward = stepAIC(binmodel_partial_3, direction = "backward")
```
From the backward elimination, the best model with lowest AIC of -8741.1 is: status ~ race + marital_status + t_stage + n_stage + differentiate + estrogen_status + progesterone_status + sqrt_examined + age.


```{r forward selection on binary Y}
binglobal_backward = stepAIC(model_global_bin, direction = "forward")
bin1_backward = stepAIC(binmodel_partial_1, direction = "forward")
bin2_backward = stepAIC(binmodel_partial_2, direction = "forward")
bin3_backward = stepAIC(binmodel_partial_3, direction = "forward")
```
From the forward selection, the best model with lowest AIC of -8737.54 status ~ race + marital_status + t_stage + n_stage + differentiate +  a_stage + estrogen_status + progesterone_status + ln_tumor + sqrt_examined + age. Backward elimination selection has lower AIC value, so we prefer backward elimination model.

```{r stepwise regression on binary numeric Y}
binglobal_backward = stepAIC(model_global_bin, direction = "both")
bin1_backward = stepAIC(binmodel_partial_1, direction = "both")
bin2_backward = stepAIC(binmodel_partial_2, direction = "both")
bin3_backward = stepAIC(binmodel_partial_3, direction = "both")
```
- From the stepwise regression, we have the lowest AIC of -8741.1 which is the model of status ~ race + marital_status + t_stage + n_stage + differentiate + estrogen_status + progesterone_status + sqrt_examined + age. The model is the same compared to the one we picked from the backward elimination. We will go with this model for futher statistical testing. 

## ANOVA
#### anova for numeric Y
```{r}
# anova for numeric Y
newbc1$ln_tumor <- ifelse(newbc1$ln_tumor <= 0, NA, newbc1$ln_tumor)

# Apply transformations
newbc1$sqrt_examined <- sqrt(newbc1$sqrt_examined)
newbc1$ln_tumor <- log(newbc1$ln_tumor)

# If you decide to remove rows with any NA values
newbc1 <- na.omit(newbc1)

# Fit the linear model
lm_model <- lm(survival_months ~ marital_status + n_stage + estrogen_status + 
               sqrt_examined + a_stage + progesterone_status + ln_tumor, 
               data = newbc1)

# Perform ANOVA
anova_result <- anova(lm_model)
print(anova_result)
```
Based on ANOVA test, matial_status, n_stage, estrogen_status, and ln_tumors are significant variables.

```{r}
# delete insignificant variables from the above anova table and fit a new model
lm_model1 <- lm(survival_months ~ marital_status + n_stage + estrogen_status + ln_tumor, 
               data = newbc1)

# Perform ANOVA
anova_result1 <- anova(lm_model1)
print(anova_result1)
```
```{r}
# Partial f test for nested model
model_reduced <- lm(survival_months ~ marital_status + n_stage + estrogen_status + ln_tumor, 
                    data = newbc1)
model_full <- lm(survival_months ~ marital_status + n_stage + estrogen_status + 
                 sqrt_examined + a_stage + progesterone_status + ln_tumor, 
                 data = newbc1)
anova(model_reduced, model_full)
```
With p significant p value,  we have enough evidence to show that the full model is better.

#### anova for binary Y
```{r}
model2 <- glm(status ~ race + marital_status + t_stage + n_stage + differentiate + estrogen_status + progesterone_status + sqrt_examined + age, data = newbc2)
anova_result1 <- anova(model2)
print(anova_result1)
summary(model2)
```

```{r}
null_model <- glm(status ~ 1, family = binomial, data = newbc2)

anova(null_model, model2, test = "Chisq")
```

With p significant p value, we have enough evidence to show that the full model is better, which is status ~ race + marital_status + t_stage + n_stage + differentiate + estrogen_status + progesterone_status + sqrt_examined + age

## Criterion procedures

3.0 transformation edited
3.1 interaction transformation ??
3.2 partial test 
3.3 diagnostic boxcox ??? 之前不是用过了boxcox
4. Step-wise: forward/ backward /AIC 
5. final model 
6. model assumption (check multicolinearity (VIF))
7. cross validation
